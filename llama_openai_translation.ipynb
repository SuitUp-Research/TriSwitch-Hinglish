{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install openai pandas python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from time import sleep\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9cfd9f",
   "metadata": {},
   "source": [
    "## 1. Setup OpenAI API\n",
    "\n",
    "Make sure to set your OpenAI API key in environment variables or .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e704b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "# Option 1: From environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Option 2: Direct assignment (not recommended for production)\n",
    "# openai.api_key = \"your-api-key-here\"\n",
    "\n",
    "if not openai.api_key:\n",
    "    print(\"WARNING: OpenAI API key not found!\")\n",
    "    print(\"Please set OPENAI_API_KEY environment variable or assign it directly.\")\n",
    "else:\n",
    "    print(\"OpenAI API key loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ee0421",
   "metadata": {},
   "source": [
    "## 2. Define Translation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847bfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_openai(texts, model=\"gpt-3.5-turbo\", temperature=0.0):\n",
    "    \"\"\"\n",
    "    Translate a list of Hinglish texts to English using OpenAI API.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of input texts to translate\n",
    "        model: OpenAI model to use (gpt-3.5-turbo, gpt-4, etc.)\n",
    "        temperature: Sampling temperature (0 = deterministic)\n",
    "    \n",
    "    Returns:\n",
    "        List of translated texts\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"You are a professional translator specializing in Hinglish to English translation. \"\n",
    "        \"Translate the given Hinglish text to natural, fluent English. \"\n",
    "        \"Preserve the meaning and intent of the original text. \"\n",
    "        \"Only provide the translation, no additional commentary.\"\n",
    "    )\n",
    "    \n",
    "    for text in texts:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"Translate to English: {text}\"}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=100\n",
    "            )\n",
    "            \n",
    "            translation = response.choices[0].message.content.strip()\n",
    "            outputs.append(translation)\n",
    "            \n",
    "            # Rate limiting - adjust as needed\n",
    "            sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error translating '{text}': {e}\")\n",
    "            outputs.append(f\"[ERROR: {str(e)}]\")\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945875e",
   "metadata": {},
   "source": [
    "## 3. Define Sentence Triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d9608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentence triplets\n",
    "sentence_triplets = [\n",
    "    {\n",
    "        \"triplet_id\": 1,\n",
    "        \"base\": \"train kaha tak jati hai\",\n",
    "        \"variant_topic_fronting\": \"kaha tak jati hai train\",\n",
    "        \"variant_emphasis_shift\": \"jati hai kaha tak train\"\n",
    "    },\n",
    "    # Add more triplets here as needed\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(sentence_triplets)} sentence triplets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f4f43",
   "metadata": {},
   "source": [
    "## 4. Translate All Variants\n",
    "\n",
    "**Note**: This will make API calls and may incur costs. Adjust the model parameter as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa32170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your model\n",
    "# Options: \"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo-preview\"\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for triplet in sentence_triplets:\n",
    "    triplet_id = triplet[\"triplet_id\"]\n",
    "    print(f\"\\nProcessing triplet {triplet_id}...\")\n",
    "    \n",
    "    # Translate each variant\n",
    "    base_trans = translate_with_openai([triplet[\"base\"]], model=MODEL)[0]\n",
    "    print(f\"  Base: {base_trans}\")\n",
    "    \n",
    "    topic_trans = translate_with_openai([triplet[\"variant_topic_fronting\"]], model=MODEL)[0]\n",
    "    print(f\"  Topic fronting: {topic_trans}\")\n",
    "    \n",
    "    emphasis_trans = translate_with_openai([triplet[\"variant_emphasis_shift\"]], model=MODEL)[0]\n",
    "    print(f\"  Emphasis shift: {emphasis_trans}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"triplet_id\": triplet_id,\n",
    "        \"variant_type\": \"base\",\n",
    "        \"input_hinglish\": triplet[\"base\"],\n",
    "        \"llm_translation\": base_trans,\n",
    "        \"model\": MODEL\n",
    "    })\n",
    "    \n",
    "    results.append({\n",
    "        \"triplet_id\": triplet_id,\n",
    "        \"variant_type\": \"topic_fronting\",\n",
    "        \"input_hinglish\": triplet[\"variant_topic_fronting\"],\n",
    "        \"llm_translation\": topic_trans,\n",
    "        \"model\": MODEL\n",
    "    })\n",
    "    \n",
    "    results.append({\n",
    "        \"triplet_id\": triplet_id,\n",
    "        \"variant_type\": \"emphasis_shift\",\n",
    "        \"input_hinglish\": triplet[\"variant_emphasis_shift\"],\n",
    "        \"llm_translation\": emphasis_trans,\n",
    "        \"model\": MODEL\n",
    "    })\n",
    "\n",
    "print(f\"\\nTranslation complete! Generated {len(results)} translations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ff1d0a",
   "metadata": {},
   "source": [
    "## 5. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for better visualization\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display grouped by triplet\n",
    "for triplet_id in df_results['triplet_id'].unique():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRIPLET {triplet_id}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    triplet_df = df_results[df_results['triplet_id'] == triplet_id]\n",
    "    \n",
    "    for _, row in triplet_df.iterrows():\n",
    "        print(f\"\\n{row['variant_type'].upper()}:\")\n",
    "        print(f\"  Input:  {row['input_hinglish']}\")\n",
    "        print(f\"  Output: {row['llm_translation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e171b7ab",
   "metadata": {},
   "source": [
    "## 6. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03478f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_file = f\"llm_translations_{MODEL.replace('-', '_')}.csv\"\n",
    "df_results.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643784f",
   "metadata": {},
   "source": [
    "## 7. Experiment with Different Prompts (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7477c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_custom_prompt(text, custom_system_prompt, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Test different system prompts for translation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": custom_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            temperature=0.0,\n",
    "            max_tokens=100\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR: {str(e)}]\"\n",
    "\n",
    "# Test different prompts\n",
    "test_sentence = \"train kaha tak jati hai\"\n",
    "\n",
    "prompts_to_test = [\n",
    "    \"Translate the following Hinglish sentence to English:\",\n",
    "    \"Convert this Hindi-English mixed text to pure English:\",\n",
    "    \"You are an expert in Hinglish. Translate to English naturally:\"\n",
    "]\n",
    "\n",
    "# for prompt in prompts_to_test:\n",
    "#     result = translate_with_custom_prompt(test_sentence, prompt)\n",
    "#     print(f\"Prompt: {prompt}\")\n",
    "#     print(f\"Result: {result}\")\n",
    "#     print()\n",
    "#     sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86688c6d",
   "metadata": {},
   "source": [
    "## 8. Load and Translate from Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927dffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load from dataset file\n",
    "# with open('dataset/db.json', 'r', encoding='utf-8') as f:\n",
    "#     dataset = json.load(f)\n",
    "\n",
    "# Process dataset...\n",
    "# Add your data loading logic here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43172bc9",
   "metadata": {},
   "source": [
    "## 9. Cost Estimation\n",
    "\n",
    "Track approximate costs for API usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate token counts and costs (as of 2024)\n",
    "# Update these based on current OpenAI pricing\n",
    "\n",
    "PRICING = {\n",
    "    \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015},  # per 1K tokens\n",
    "    \"gpt-4\": {\"input\": 0.03, \"output\": 0.06},\n",
    "    \"gpt-4-turbo-preview\": {\"input\": 0.01, \"output\": 0.03}\n",
    "}\n",
    "\n",
    "def estimate_cost(num_sentences, model=\"gpt-3.5-turbo\", avg_tokens_per_sentence=50):\n",
    "    \"\"\"\n",
    "    Estimate the cost of translation.\n",
    "    \"\"\"\n",
    "    if model not in PRICING:\n",
    "        return \"Unknown model\"\n",
    "    \n",
    "    input_tokens = num_sentences * avg_tokens_per_sentence\n",
    "    output_tokens = num_sentences * avg_tokens_per_sentence * 0.8  # Assume slightly shorter output\n",
    "    \n",
    "    input_cost = (input_tokens / 1000) * PRICING[model][\"input\"]\n",
    "    output_cost = (output_tokens / 1000) * PRICING[model][\"output\"]\n",
    "    \n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"sentences\": num_sentences,\n",
    "        \"estimated_input_tokens\": input_tokens,\n",
    "        \"estimated_output_tokens\": output_tokens,\n",
    "        \"estimated_cost_usd\": round(total_cost, 4)\n",
    "    }\n",
    "\n",
    "# Estimate cost for your dataset\n",
    "num_translations = len(results)\n",
    "cost_estimate = estimate_cost(num_translations, MODEL)\n",
    "print(\"Cost Estimate:\")\n",
    "for key, value in cost_estimate.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
